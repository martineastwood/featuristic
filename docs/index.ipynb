{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# What is Featuristic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![featuristic_logo](_static/logo.png \"Featuristic\")\n",
    "\n",
    "**Featuristic** uses Genetic Algorithms to automate the process of **feature engineering** and **feature selection**, enhancing the performance of machine learning models by optimizing their predictive capabilities.\n",
    "\n",
    "## Understanding Genetic Feature Synthesis\n",
    "\n",
    "Featuristic uses a technique known as symbolic regression to intelligently generate interpretable mathematical formulas, which are then used to construct new features from your dataset.\n",
    "\n",
    "Initially, Featuristic creates a diverse population of formulas using fundamental mathematical operators such as `add`, `subtract`, `sin`, `tan`, `square`, `sqrt`, and more.\n",
    "\n",
    "For instance, a formula generated by Featuristic might look like this: `(abs(square(feature_1)) - feature_2) * feature_3`.\n",
    "\n",
    "Next, Featuristic evaluates the performance of these formulas by measuring how well the features they generate correlate with the target variable. The formulas that produce features with the highest correlation are then selected and combined using a genetic algorithm to create offspring, as shown below.\n",
    "\n",
    "![Symbolic Regression Example](_static/symbolic_regression_example.png \"Symbolic Regression Example\")\n",
    "\n",
    "These offspring may also undergo point mutations, altering specific operators within the formula, as illustrated below.\n",
    "\n",
    "![Mutation Example](_static/mutation_example.png \"Mutation Example\")\n",
    "\n",
    "This iterative process continues across multiple generations, continually refining the population of formulas with the goal of generating features that exhibit strong correlations with the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Below is a simple example of how Featuristic performs automated feature engineering and selection on the widely used `cars` dataset.\n",
    "\n",
    "Featuristic operates in two distinct steps:\n",
    "\n",
    "1. **Genetic Feature Synthesis:** In this initial phase, Featuristic intelligently evolves new features through a form of symbolic regression. This involves the generation of mathematical expressions using genetic algorithms. These expressions are designed to capture complex relationships within the dataset.\n",
    "\n",
    "2. **Genetic Feature Selection:** Following the creation of new features, Featuristic employs a Genetic Feature Selection algorithm. This algorithm searches through the newly formed feature space to identify the most optimal subset of features. The objective is to maximize predictive accuracy while minimizing the number of features required for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import featuristic as ft\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(8888)\n",
    "\n",
    "print(ft.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>displacement</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307.0</td>\n",
       "      <td>8</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>350.0</td>\n",
       "      <td>8</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>318.0</td>\n",
       "      <td>8</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304.0</td>\n",
       "      <td>8</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302.0</td>\n",
       "      <td>8</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   displacement  cylinders  horsepower  weight  acceleration  model_year  \\\n",
       "0         307.0          8       130.0    3504          12.0          70   \n",
       "1         350.0          8       165.0    3693          11.5          70   \n",
       "2         318.0          8       150.0    3436          11.0          70   \n",
       "3         304.0          8       150.0    3433          12.0          70   \n",
       "4         302.0          8       140.0    3449          10.5          70   \n",
       "\n",
       "   origin  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = ft.fetch_cars_dataset()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18.0\n",
       "1    15.0\n",
       "2    18.0\n",
       "3    16.0\n",
       "4    17.0\n",
       "Name: mpg, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Genetic Feature Synthesis\n",
    "\n",
    "Now, let's dive into the exciting part: running the Genetic Feature Synthesis to automatically engineer new features from our dataset!\n",
    "\n",
    "Before we proceed, it's important to ensure a robust evaluation of our model's performance. To achieve this, we'll first split our dataset into training and testing sets. The training set will be used to train our model, while the testing set will remain unseen during the training process and will serve as an independent dataset to evaluate the model's performance.\n",
    "\n",
    "Once our data is appropriately split, we'll initiate the Genetic Feature Synthesis process. We've configured the genetic algorithm to  synthesize 10 new features for us. This entails evolving a population consisting of 100 individuals iteratively over 50 generations. To ensure optimal performance, we've set the genetic algorithm to halt early if it fails to improve upon the best feature identified within 25 generations. Additionally, for enhanced computational efficiency, we've designated `n_jobs` as -1, enabling concurrent execution across all available CPUs on our computer.\n",
    "\n",
    "With everything set up, we simply call the `fit` function to generate our new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating new features...:  48%|████████████████████████████████████████▊                                            | 24/50 [00:06<00:05,  4.89it/s]/Users/martin/repos/featuristic/.venv/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in sin\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m      3\u001b[0m synth \u001b[38;5;241m=\u001b[39m ft\u001b[38;5;241m.\u001b[39mGeneticFeatureSynthesis(\n\u001b[1;32m      4\u001b[0m     num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      5\u001b[0m     population_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[43msynth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/featuristic/src/featuristic/synthesis/genetic_feature_synthesis.py:249\u001b[0m, in \u001b[0;36mGeneticFeatureSynthesis.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    247\u001b[0m fitness \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    248\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation\u001b[38;5;241m.\u001b[39mevaluate(X_copy)\n\u001b[0;32m--> 249\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_fitness\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfitness_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparsimony_coefficient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_copy\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prog, score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation\u001b[38;5;241m.\u001b[39mpopulation, score):\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# check for the best program\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     fitness\u001b[38;5;241m.\u001b[39mappend(score)\n",
      "File \u001b[0;32m~/repos/featuristic/src/featuristic/synthesis/population.py:108\u001b[0m, in \u001b[0;36mBasePopulation.compute_fitness\u001b[0;34m(self, fitness_func, parsimony_coefficient, prediction, y)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_fitness\u001b[39m(\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     80\u001b[0m     fitness_func: Callable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m     y: pd\u001b[38;5;241m.\u001b[39mSeries,\n\u001b[1;32m     84\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    Compute the fitness of the population.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m        The fitness of the population.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfitness_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparsimony_coefficient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m~/repos/featuristic/src/featuristic/synthesis/population.py:109\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_fitness\u001b[39m(\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     80\u001b[0m     fitness_func: Callable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m     y: pd\u001b[38;5;241m.\u001b[39mSeries,\n\u001b[1;32m     84\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    Compute the fitness of the population.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m        The fitness of the population.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     score \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 109\u001b[0m         \u001b[43mfitness_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparsimony_coefficient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m prog, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation, prediction)\n\u001b[1;32m    111\u001b[0m     ]\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m~/repos/featuristic/src/featuristic/synthesis/fitness.py:92\u001b[0m, in \u001b[0;36mfitness_pearson\u001b[0;34m(program, parsimony, y_true, y_pred)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mptp(y_true) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39mptp(y_pred) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmaxsize\n\u001b[0;32m---> 92\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(\u001b[43mpearsonr\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstatistic)\n\u001b[1;32m     93\u001b[0m penalty \u001b[38;5;241m=\u001b[39m node_count(program) \u001b[38;5;241m*\u001b[39m parsimony\n\u001b[1;32m     94\u001b[0m loss \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m penalty\n",
      "File \u001b[0;32m~/repos/featuristic/.venv/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4796\u001b[0m, in \u001b[0;36mpearsonr\u001b[0;34m(x, y, alternative, method)\u001b[0m\n\u001b[1;32m   4791\u001b[0m ym \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mastype(dtype) \u001b[38;5;241m-\u001b[39m ymean\n\u001b[1;32m   4793\u001b[0m \u001b[38;5;66;03m# Unlike np.linalg.norm or the expression sqrt((xm*xm).sum()),\u001b[39;00m\n\u001b[1;32m   4794\u001b[0m \u001b[38;5;66;03m# scipy.linalg.norm(xm) does not overflow if xm is, for example,\u001b[39;00m\n\u001b[1;32m   4795\u001b[0m \u001b[38;5;66;03m# [-5e210, 5e210, 3e200, -3e200]\u001b[39;00m\n\u001b[0;32m-> 4796\u001b[0m normxm \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4797\u001b[0m normym \u001b[38;5;241m=\u001b[39m linalg\u001b[38;5;241m.\u001b[39mnorm(ym)\n\u001b[1;32m   4799\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-13\u001b[39m\n",
      "File \u001b[0;32m~/repos/featuristic/.venv/lib/python3.11/site-packages/scipy/linalg/_misc.py:146\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(a, ord, axis, keepdims, check_finite)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Differs from numpy only in non-finite handling and the use of blas.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_finite:\n\u001b[0;32m--> 146\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray_chkfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(a)\n",
      "File \u001b[0;32m~/repos/featuristic/.venv/lib/python3.11/site-packages/numpy/lib/function_base.py:630\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    628\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar \u001b[38;5;129;01min\u001b[39;00m typecodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllFloat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(a)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray must not contain infs or NaNs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "synth = ft.GeneticFeatureSynthesis(\n",
    "    num_features=10,\n",
    "    population_size=100,\n",
    "    max_generations=50,\n",
    "    early_termination_iters=25,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "synth.fit(X_train, y_train)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we call the `transform` function to generate a dataframe containing our new features. By default, the `GeneticFeatureSynthesis` class will return both the original features and the newly synthesised features. However, we return just the new features by setting the `return_all_features` argument to False when we create the class. \n",
    "\n",
    "We can also combine both the `fit` and `transform` steps into one step by calling `fit_transform` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = synth.transform(X_train)\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our newly engineered features currently have generic names. However, since Featuristic synthesizes these features by the applying mathematical expressions to the data, we can look at the underlying formulas responsible for each feature's creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = synth.get_feature_info()\n",
    "info[[\"name\", \"formula\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "Following the synthesis of new features, the next step involves using another genetic algorithm for feature selection. This process sifts through the pool of generated features to identify the subset that optimally contributes to predictive performance while minimizing redundancy. \n",
    "\n",
    "Through iterative refinement, this algorithm aims to strike a balance between predictive power and model complexity, culminating in an optimized feature set integrating into your machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Define the Cost Function\n",
    "\n",
    "We set up a custom ojective function that the Genetic Feature Selection algorithm will use to quantify how well the subset of features predicts the target. Please note that the function should return a value to minimize so a smaller value is better. If you want to maximize a metric, you should multiply the output of your objective_function by -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective_function(X, y):\n",
    "    model = LinearRegression()\n",
    "    scores = cross_val_score(model, X, y, cv=3, scoring=\"neg_mean_absolute_error\")\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up the Genetic Feature Selector. We've configured the genetic algorithm to evolve a population consisting of 100 individuals iteratively over 50 generations. To ensure optimal performance, we've set the genetic algorithm to halt early if it fails to improve upon the best feature set identified within 15 generations. Additionally, for enhanced computational efficiency, we've designated `n_jobs` as -1, enabling concurrent execution across all available CPUs on our computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "selector = ft.GeneticFeatureSelector(\n",
    "    objective_function,\n",
    "    population_size = 100,\n",
    "    max_generations = 50,\n",
    "    early_termination_iters = 15,\n",
    "    n_jobs = -1,\n",
    ")\n",
    "\n",
    "selector.fit(features, y_train)\n",
    "\n",
    "selected_features = selector.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### The New Features\n",
    "\n",
    "Let's print out our new features to see what was generated for us. You can see that featurize has kept three of the original features (\"displacement\", \"cylinders\", \"origin\") and has kept four of the features created via the Genetic Feature Synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "original_mae = mean_absolute_error(y_test, preds)\n",
    "original_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(features, y_train)\n",
    "\n",
    "test_features = synth.transform(X_test)\n",
    "preds = model.predict(test_features)\n",
    "featurized_mae = mean_absolute_error(y_test, preds)\n",
    "featurized_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Original MAE: {original_mae}, Featuristic MAE: {featurized_mae}, \\\n",
    "    Improvement: {round((1 - (featurized_mae / original_mae))* 100, 1)}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    ".. toctree::\n",
    "   :maxdepth: 1\n",
    "\n",
    "   install/index\n",
    "   getting_started/index\n",
    "   guides/index   \n",
    "\n",
    ".. toctree::\n",
    "   :maxdepth: 1\n",
    "   :caption: Resources & References\n",
    "\n",
    "   release_notes\n",
    "   api_reference"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Other Links\n",
    "------------------\n",
    "\n",
    "* :ref:`genindex`\n",
    "* :ref:`search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
