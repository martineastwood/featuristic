{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d07cf18d",
   "metadata": {},
   "source": [
    "# üß© Genetic Feature Synthesis\n",
    "\n",
    "The `GeneticFeatureSynthesis` class is the main interface for generating new symbolic features using **Genetic Feature Synthesis (GFS)**.\n",
    "\n",
    "It acts as a scikit-learn-compatible transformer (`fit`, `transform`, `fit_transform`) that automatically evolves **interpretable mathematical expressions** from your input features and selects the best ones based on predictive performance.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Parameters\n",
    "\n",
    "| Argument | Type | Description | Default Value |\n",
    "|---|---|---|---|\n",
    "| `num_features` | `int` | The number of best features to generate. Internally, `3 * num_features` programs are generated, and the best `num_features` are selected via Maximum Relevance Minimum Redundancy (mRMR). | `10` |\n",
    "| `population_size` | `int` | The number of programs in each generation. A larger population increases the likelihood of finding a good solution but also increases computation time. | `50` |\n",
    "| `max_generations` | `int` | The maximum number of generations to run. More generations can lead to better solutions but will take longer. | `25` |\n",
    "| `tournament_size` | `int` | The size of the tournament for parent selection. A larger size increases the chance of selecting fitter programs but requires more computation. | `7` |\n",
    "| `crossover_proba` | `float` (0-1) | The probability of crossover mutation occurring between selected parents in each generation. | `0.75` |\n",
    "| `parsimony_coefficient` | `float` | Controls the penalty for larger programs. Higher values encourage smaller, more interpretable features by penalizing complexity. This helps prevent \"bloat\". | `0.001` |\n",
    "| `adaptive_parsimony` | `bool` | Whether to dynamically adjust the parsimony coefficient over generations based on the average program size. This can help manage complexity as evolution progresses. | `True` |\n",
    "| `early_termination_iters` | `int` | If the best score does not improve for this number of consecutive generations, the algorithm will terminate early. | `15` |\n",
    "| `functions` | `List[str]` or `List[SymbolicFunction]` | A list of functions to use when constructing symbolic programs. If `None`, all built-in functions are used. Functions must be names returned by `list_symbolic_functions`. | `None` (all built-in) |\n",
    "| `custom_functions` | `List[SymbolicFunction]` | A list of user-defined custom functions to include in the programs. Each function must be an instance of the `CustomSymbolicFunction` class. | `None` |\n",
    "| `fitness_function` | `str` or `Callable` | The metric used to evaluate the fitness of programs (e.g., `\"pearson\"`, `\"r2\"`, `\"log_loss\"`). If `None`, the fitness function is inferred based on the target type (e.g., Pearson correlation for regression, Log Loss for classification). | `None` (inferred) |\n",
    "| `return_all_features` | `bool` | If `True`, the `transform` method will return both the original input features and the newly synthesized features. If `False`, only the synthesized features will be returned. | `True` |\n",
    "| `n_jobs` | `int` | The number of CPU cores to use for parallel processing. Set to `-1` to use all available cores. If `1`, computations run serially. | `-1` (all cores) |\n",
    "| `show_progress_bar` | `bool` | Whether to display a progress bar during the evolutionary process. | `True` |\n",
    "| `verbose` | `bool` | If `True`, additional information, such as generation progress and the best program found in each generation, will be printed. | `False` |\n",
    "| `min_constant_val` | `float` | The minimum value for ephemeral random constants generated within programs. | `-10.0` |\n",
    "| `max_constant_val` | `float` | The maximum value for ephemeral random constants generated within programs. | `10.0` |\n",
    "| `include_constants` | `bool` | Whether to allow the generation of ephemeral random constants in the symbolic programs. If `False`, programs will only use input features and functions. | `True` |\n",
    "| `optimize_constants` | `bool` | Whether to optimize the constant values within the generated programs using a numerical optimization routine. | `True` |\n",
    "| `constant_optimization_maxiter` | `int` | The maximum number of iterations for the constant optimization process. | `100` |\n",
    "| `const_prob` | `float` | The probability of generating a constant leaf node during program creation. | `0.15` |\n",
    "| `stop_prob` | `float` | The probability of stopping the program generation when building new programs (influences program size and depth). | `0.8` |\n",
    "| `max_depth` | `int` | The maximum allowed depth of the generated symbolic programs. Deeper programs can be more complex. | `3` |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è How it Works\n",
    "\n",
    "1. **Initialization**:\n",
    "   - A random population of symbolic programs is created from your input features and available symbolic functions.\n",
    "\n",
    "2. **Evolution**:\n",
    "   - Over multiple generations:\n",
    "    - Each program is evaluated using a fitness function (e.g., correlation with the target)\n",
    "    - Top programs are selected via tournament selection\n",
    "    - Offspring are generated via crossover and mutation\n",
    "\n",
    "3. **Selection (mRMR)**:\n",
    "   - After evolution, the best programs are filtered using Maximum Relevance Minimum Redundancy (mRMR) to ensure that selected features are:\n",
    "     - Highly predictive\n",
    "     - Minimally redundant\n",
    "\n",
    "4. **Transformation**:\n",
    "   - The best programs are used to transform data in `.transform()` or `.fit_transform()`.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Methods\n",
    "\n",
    "### `.fit(X, y)`\n",
    "\n",
    "Train the feature synthesizer on your dataset. Evolves symbolic expressions predictive of the target `y`.\n",
    "\n",
    "### `.transform(X)`\n",
    "\n",
    "Apply the top symbolic formulas to new input data `X`, returning new synthesized features.\n",
    "\n",
    "### `.fit_transform(X, y)`\n",
    "\n",
    "Convenient method to run `.fit()` and `.transform()` in one step.\n",
    "\n",
    "### `.get_feature_info()`\n",
    "\n",
    "Returns a pandas.DataFrame showing:\n",
    "\n",
    "- **name**: Auto-generated feature name\n",
    "- **formula**: The final simplified symbolic formula\n",
    "- **raw_formula**: The original (possibly unsimplified) formula\n",
    "- **fitness**: The final score used for selection\n",
    "\n",
    "### `.plot_history()`\n",
    "\n",
    "Generates a line plot of:\n",
    "\n",
    "- Best fitness per generation\n",
    "- Parsimony coefficient (if adaptive)\n",
    "- Early stopping indicator\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Example\n",
    "\n",
    "```python\n",
    "from featuristic import GeneticFeatureSynthesis\n",
    "from featuristic.datasets import fetch_wine_dataset\n",
    "\n",
    "X, y = fetch_wine_dataset()\n",
    "\n",
    "gfs = GeneticFeatureSynthesis(num_features=5, max_generations=30)\n",
    "X_new = gfs.fit_transform(X, y)\n",
    "\n",
    "gfs.get_feature_info()\n",
    "gfs.plot_history()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Tip\n",
    "\n",
    "- Set `adaptive_parsimony=True` to automatically discourage overly complex features as the search progresses.\n",
    "- Want transparency? Set `verbose=True` to print the best symbolic formula every generation.\n",
    "- Need to restrict operations? Use `functions=[\"add\", \"log\", \"sqrt\"]` to limit what expressions are allowed.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
