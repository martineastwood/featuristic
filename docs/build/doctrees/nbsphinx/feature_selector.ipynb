{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b680ceb",
   "metadata": {},
   "source": [
    "# üß∞ Genetic Feature Selector\n",
    "\n",
    "The `GeneticFeatureSelector` class performs **feature selection** using binary genetic evolution. It searches for the optimal subset of features that **minimizes a user-defined objective function**.\n",
    "\n",
    "This is a powerful alternative to wrapper-based or greedy feature selection techniques like RFE or SelectKBest - especially useful when feature interactions and nonlinearity matter.\n",
    "\n",
    "---\n",
    "\n",
    "## How It Works\n",
    "\n",
    "1. Each candidate solution (called a genome) is a binary vector where each bit represents a feature.\n",
    "2. A value of 1 means the feature is selected; 0 means it‚Äôs excluded.\n",
    "3. Each genome is evaluated by a custom objective function, such as:\n",
    "\n",
    "```python\n",
    "def objective(X, y):\n",
    "    model = Ridge().fit(X, y)\n",
    "    return mean_squared_error(y, model.predict(X))\n",
    "```\n",
    "\n",
    "4. The best-scoring individuals evolve over generations using:\n",
    "\n",
    "- Tournament selection\n",
    "- Crossover\n",
    "- Mutation\n",
    "\n",
    "5. After convergence, the best subset of features is returned.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Parameters\n",
    "\n",
    "\n",
    "| Parameter                 | Type       | Description                                                   |\n",
    "| ------------------------- | ---------- | ------------------------------------------------------------- |\n",
    "| `objective_function`      | `Callable` | Function to evaluate the quality of a selected feature subset |\n",
    "| `population_size`         | `int`      | Number of binary genomes in each generation                   |\n",
    "| `max_generations`         | `int`      | Maximum number of generations                                 |\n",
    "| `tournament_size`         | `int`      | Size of tournament during parent selection                    |\n",
    "| `crossover_proba`         | `float`    | Probability of crossover between selected parents             |\n",
    "| `mutation_proba`          | `float`    | Probability that a gene (bit) is flipped                      |\n",
    "| `early_termination_iters` | `int`      | Stop early if no improvement for this many generations        |\n",
    "| `n_jobs`                  | `int`      | Number of parallel jobs to use for evaluation                 |\n",
    "| `show_progress_bar`       | `bool`     | Show progress bar during evolution (for serial runs)          |\n",
    "| `verbose`                 | `bool`     | Print messages for early stopping and best scores             |\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Methods\n",
    "\n",
    "`fit(X, y)`\n",
    "Runs evolutionary search to find the best subset of features for minimizing the objective_function.\n",
    "\n",
    "`transform(X)`\n",
    "Returns a new X containing only the selected columns.\n",
    "\n",
    "`fit_transform(X, y)`\n",
    "Combines fit and transform in one step.\n",
    "\n",
    "`plot_history()`\n",
    "Plots the best and median score per generation.\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Example\n",
    "\n",
    "```python\n",
    "from featuristic import GeneticFeatureSelector\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define a fitness function\n",
    "def objective(X_subset, y):\n",
    "    model = Ridge().fit(X_subset, y)\n",
    "    preds = model.predict(X_subset)\n",
    "    return mean_squared_error(y, preds)\n",
    "\n",
    "# Initialize the selector\n",
    "selector = GeneticFeatureSelector(\n",
    "    objective_function=objective,\n",
    "    population_size=40,\n",
    "    max_generations=50,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Plot history\n",
    "selector.plot_history()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Why Use FeatureSelector?\n",
    "\n",
    "| Goal                                                        | Use This                   |\n",
    "| ----------------------------------------------------------- | -------------------------- |\n",
    "| You want to **select** the best subset of existing features | ‚úÖ                          |\n",
    "| You want to **generate new symbolic features**              | ‚ùå Use `GeneticFeatureSynthesis`   |\n",
    "| You want to optimize any custom metric or model             | ‚úÖ                          |\n",
    "| You want feature ranking or scoring only                    | ‚ùå Use filter-based methods |\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Tips\n",
    "\n",
    "- Your objective_function can use any estimator, cross-validation, or scoring logic.\n",
    "- Set `n_jobs=-1` to parallelize evaluations for large populations.\n",
    "- Set `early_termination_iters` to avoid long-running searches when the solution plateaus."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
