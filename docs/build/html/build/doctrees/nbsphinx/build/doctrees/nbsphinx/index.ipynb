{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# What is Featuristic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![featuristic_logo](_static/logo.png \"Featuristic\")\n",
    "\n",
    "Featuristic is an automated feature engineering library based on Evolutionary Feature Synthesis. It leverages symbolic regression, genetic programming, and information-theoretic pruning to discover high-quality features from raw data without human-crafted heuristics.\n",
    "\n",
    "The features generated by EFS are model-agnostic and can be used with any downstream estimator (e.g., XGBoost, SVM, Random Forests, etc.).\n",
    "\n",
    "Whether you're working with classification or regression problems, Featuristic intelligently builds new, interpretable features using a combination of mathematical operations and evolutionary search.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Introduction to Evolutionary Feature Synthesis (EFS)\n",
    "\n",
    "**Evolutionary Feature Synthesis (EFS)** is a symbolic feature engineering framework that automatically discovers high-value, interpretable features using genetic programming and symbolic regression.\n",
    "\n",
    "EFS generates mathematical expressions (e.g. `log(abs(feature_1 - feature_2)) * sin(feature_3)`) that capture nonlinear patterns and interactions in your data, without manual intervention.\n",
    "\n",
    "It balances **predictive power** with **interpretability**, helping you build transparent models and understand the transformations behind your features.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Feature Synthesis?\n",
    "\n",
    "Feature synthesis is the process of automatically generating **new features** from existing raw inputs to improve model performance. This typically involves:\n",
    "\n",
    "- Mathematical transformations (e.g., log, square root)\n",
    "- Combinations of variables (e.g., ratios, differences, products)\n",
    "- Interaction terms (e.g., `feature_1 * sin(feature_2)`)\n",
    "\n",
    "Where traditional approaches rely on manual feature crafting or opaque embeddings, **EFS** builds these transformations **automatically** using **symbolic programs** evolved through **genetic programming**.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Symbolic Regression for Feature Engineering?\n",
    "\n",
    "Symbolic regression is a form of regression that searches the space of **symbolic expressions** to model relationships between inputs and outputs.\n",
    "\n",
    "Unlike linear models or neural networks, symbolic regression:\n",
    "\n",
    "- Produces **closed-form equations** you can read and interpret\n",
    "- Captures **nonlinear** and **combinatorial** relationships\n",
    "- Can work with small-to-medium tabular datasets\n",
    "- Offers **transparency** over \"black-box\" feature generators\n",
    "\n",
    "EFS leverages symbolic regression not to model the target directly, but to **synthesize new input features** that make your final model more effective.\n",
    "\n",
    "---\n",
    "\n",
    "## Core Concepts\n",
    "\n",
    "### üßÆ Symbolic Programs\n",
    "\n",
    "EFS represents each candidate feature as a **tree-structured symbolic program**, where:\n",
    "- Leaf nodes are input features (e.g., `feature_1`)\n",
    "- Internal nodes are symbolic functions (e.g., `log`, `sin`, `+`, `*`)\n",
    "- The output is a mathematical expression, like:\n",
    "  \n",
    "  ```text\n",
    "  log(abs(feature_1 - feature_2)) * sin(feature_3)\n",
    "  ```\n",
    "\n",
    "  Each program is stored as a dictionary tree structure and evaluated directly on your dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### üß¨ Genetic Programming\n",
    "\n",
    "EFS evolves its population of symbolic programs using genetic programming, an evolutionary algorithm inspired by natural selection.\n",
    "\n",
    "Each generation:\n",
    "\n",
    "- Evaluates each program on the data using a fitness function (e.g., correlation with the target)\n",
    "- Selects the best-performing programs via tournament selection\n",
    "- Applies:\n",
    "  - Crossover: combines subtrees from two parents\n",
    "  - Mutation: replaces random nodes with new subtrees\n",
    "  - Forms a new generation and repeats\n",
    "\n",
    "This process allows symbolic programs to evolve toward more predictive and concise forms over time.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÇÔ∏è Parsimony and Overfitting\n",
    "\n",
    "Symbolic programs can easily grow in size without improving fitness, a problem known as bloat.\n",
    "\n",
    "To combat this, EFS uses a parsimony coefficient, which penalizes large programs during fitness evaluation:\n",
    "\n",
    "```text\n",
    "fitness = raw_score / (program_size ** parsimony_coefficient)\n",
    "```\n",
    "\n",
    "This helps ensure that features remain **interpretable**, **efficient**, and **less prone to overfitting**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Maximum Relevance, Minimum Redundancy (mRMR)\n",
    "\n",
    "After several generations, EFS may have hundreds of candidate features. To select the best ones, it applies **Maximum Relevance Minimum Redundancy (mRMR)**:\n",
    "\n",
    "- **Relevance**: How strongly a feature correlates with the target\n",
    "- **Redundancy**: How much a feature overlaps with other features\n",
    "\n",
    "mRMR selects a subset of features that are both:\n",
    "\n",
    "- **Highly predictive**\n",
    "- **Diverse** (i.e., not just duplicates of each other)\n",
    "\n",
    "This ensures your final feature set is both powerful and complementary.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    ".. toctree::\n",
    "   :maxdepth: 1\n",
    "   :caption: Table of Contents\n",
    "\n",
    "   quickstart\n",
    "   feature_synthesis\n",
    "   feature_selector\n",
    "   fitness\n",
    "   custom_functions\n",
    "   scikitlearn\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "text/restructuredtext",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Other Links\n",
    "------------------\n",
    "\n",
    "* :ref:`genindex`\n",
    "* :ref:`search`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
