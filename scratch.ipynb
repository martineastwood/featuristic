{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Featuristic: Advanced Feature Engineering Pipeline\n",
    "\n",
    "This notebook demonstrates an optimized `featuristic` pipeline. We improve the results by:\n",
    "1. **Increasing Search Resources**: Larger population and more generations for deeper exploration.\n",
    "2. **Cross-Validated Selection**: Using 5-fold cross-validation in the feature selector to ensure features generalize.\n",
    "3. **Complexity Control**: Tuning the parsimony coefficient to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss, ConfusionMatrixDisplay\n",
    "from featuristic import FeatureSynthesizer, FeatureSelector\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading",
   "metadata": {},
   "source": [
    "## 1. Create a Challenging Dataset\n",
    "\n",
    "We'll generate a synthetic classification dataset with 20 features to make selection more relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_prep",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw, y = make_classification(\n",
    "    n_samples=1000, \n",
    "    n_features=20, \n",
    "    n_informative=7, \n",
    "    n_redundant=4, \n",
    "    flip_y=0.1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "feature_names = [f\"feature_{i}\" for i in range(20)]\n",
    "X = pd.DataFrame(X_raw, columns=feature_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training set shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline_header",
   "metadata": {},
   "source": [
    "## 2. Baseline Model (Raw Features)\n",
    "\n",
    "Standard Logistic Regression on the original 20 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baseline_train",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = LogisticRegression(max_iter=1000)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "acc_baseline = accuracy_score(y_test, baseline_model.predict(X_test))\n",
    "print(f\"Baseline Accuracy: {acc_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featuristic_header",
   "metadata": {},
   "source": [
    "## 3. Advanced Feature Synthesis\n",
    "\n",
    "We increase the `population_size` and `generations` to find more powerful features, and lower the `parsimony_coefficient` to allow for slightly more complex expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "syntax_fit",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth = FeatureSynthesizer(\n",
    "    n_features=25, \n",
    "    population_size=250,   # Increased from 100\n",
    "    generations=250,        # Increased from 20\n",
    "    parsimony_coefficient=0.0001, # Lowered from 0.001 to allow more complexity\n",
    "    verbose=True, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create synthetic features\n",
    "X_train_synth = synth.fit_transform(X_train, y_train)\n",
    "X_test_synth = synth.transform(X_test)\n",
    "\n",
    "# Combine with original features\n",
    "X_train_combined = np.hstack([X_train, X_train_synth])\n",
    "X_test_combined = np.hstack([X_test, X_test_synth])\n",
    "\n",
    "combined_names = feature_names + [f\"synth_{i}\" for i in range(25)]\n",
    "X_train_combined = pd.DataFrame(X_train_combined, columns=combined_names)\n",
    "X_test_combined = pd.DataFrame(X_test_combined, columns=combined_names)\n",
    "\n",
    "print(f\"Combined features shape: {X_train_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d77e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth.plot_convergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5666e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prog in synth.get_programs()[:5]:\n",
    "    print(prog[\"expression\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f9beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_model = LogisticRegression(max_iter=1000)\n",
    "all_features_model.fit(X_train_combined, y_train)\n",
    "acc_all_features = accuracy_score(y_test, all_features_model.predict(X_test_combined))\n",
    "print(f\"All Features Accuracy: {acc_all_features:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selector_header",
   "metadata": {},
   "source": [
    "## 4. Robust Evolutionary Feature Selection\n",
    "\n",
    "We optimize the selector by using **5-fold cross-validation** within the objective function. This helps prevent selecting features that only work well on the training split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selector_fit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a robust objective: minimize negative CV accuracy\n",
    "def objective(X_subset, y):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    # Use cross-validation for a more stable estimate of performance\n",
    "    scores = cross_val_score(\n",
    "        model, X_subset, y, cv=3, scoring='neg_log_loss', n_jobs=-1\n",
    "    )\n",
    "    return -scores.mean()\n",
    "\n",
    "selector = FeatureSelector(\n",
    "    objective_function=objective, \n",
    "    population_size=50,  # Increased for better search\n",
    "    max_generations=20,    # Increased for better search\n",
    "    verbose=True, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_final = selector.fit_transform(X_train_combined, y_train)\n",
    "X_test_final = selector.transform(X_test_combined)\n",
    "\n",
    "print(f\"Selected {len(selector.selected_features_)} features: {selector.selected_features_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.plot_convergence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_header",
   "metadata": {},
   "source": [
    "## 5. Final Comparison\n",
    "\n",
    "Compare the baseline with the advanced engineered pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = LogisticRegression(max_iter=1000)\n",
    "final_model.fit(X_train_final, y_train)\n",
    "\n",
    "y_pred_final = final_model.predict(X_test_final)\n",
    "acc_final = accuracy_score(y_test, y_pred_final)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, baseline_model.predict(X_test), ax=ax1, cmap='Blues')\n",
    "ax1.set_title(f'Baseline (20 Features)\\nAccuracy: {acc_baseline:.4f}')\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_final, ax=ax2, cmap='Greens')\n",
    "ax2.set_title(f'Advanced Pipeline ({len(selector.selected_features_)} Features)\\nAccuracy: {acc_final:.4f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "improvement = (acc_final - acc_baseline) / acc_baseline * 100\n",
    "print(f\"Final Accuracy Improvement: {improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63124268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
